#!/usr/bin/python3
# Optimise filter configurations for ld-chroma-decoder using a genetic
# algorithm. Performance is evaluated by encoding test material with
# ld-chroma-encoder and measuring the similarity of the decoded result using
# SSIM.

# XXX There's a lot of duplication between the ffmpeg commands...
# XXX Try generating an NTSC 3D FFT filter

import PIL.Image
import PIL.ImageDraw
import hashlib
import logging
import os
import random
import statistics
import subprocess
import sys
import time

logging.basicConfig(level=logging.INFO)

testsuite_dir = os.path.realpath(os.path.dirname(sys.argv[0]))
lddecode_dir = os.path.join(testsuite_dir, "..", "ld-decode")

cache_dir = os.path.join(testsuite_dir, "cache", "evaluate")
os.makedirs(cache_dir, exist_ok=True)

tmp_dir = "/var/tmp/lddtest/evaluate"
os.makedirs(tmp_dir, exist_ok=True)

class TestVideo:
    """A video testcase."""

    def __init__(self, name):
        self.name = name

        self.rgbname = os.path.join(cache_dir, name + ".rgb")
        if not os.path.exists(self.rgbname):
            logging.info("Generating %s", self.rgbname)
            self.generate()

        self.tbcname = os.path.join(cache_dir, name + ".tbc")
        if not os.path.exists(self.tbcname):
            logging.info("Encoding %s", self.tbcname)
            self.encode()

    def generate(self):
        """Generate the .rgb through whatever mechanism.
        Subclasses should override this."""

        raise NotImplementedError("generate")

    def encode(self):
        """Encode the .rgb into a .tbc."""

        # XXX assumes PAL
        subprocess.check_call([
            os.path.join(lddecode_dir, "tools", "ld-chroma-decoder", "encoder", "ld-chroma-encoder"),
            self.rgbname, self.tbcname,
            ])

class LAVTestVideo(TestVideo):
    """A video testcase generated from a libavfilter test source."""

    def __init__(self, name, source):
        self.source = source
        if "=" in source:
            self.source += ":"
        else:
            self.source += "="
        self.source += "duration=1:size=922x576:rate=25"
        super(LAVTestVideo, self).__init__(name)

    def generate(self):
        subprocess.check_call(["ffmpeg", "-loglevel", "error",
            "-f", "lavfi", "-i", self.source,
            "-filter:v", "pad=928:576:-1:-1",
            "-f", "rawvideo", "-pix_fmt", "rgb48", "-s", "928x576", "-y", self.rgbname,
            ])

class VQEGTestVideo(TestVideo):
    """A video testcase generated from one of the VQEG test sequences.
    These can be downloaded from <https://media.xiph.org/vqeg/TestSequences/>."""

    # XXX could download into the cache dir automatically
    vqeg_dir = "/n/stuff/tv/Test/vqeg"

    def __init__(self, name, yuvname):
        self.yuvname = os.path.join(self.vqeg_dir, yuvname)
        super(VQEGTestVideo, self).__init__(name)

    def generate(self):
        insize = "720x576"
        inrate = "25"
        filters = "scale=922:576,pad=928:576:-1:-1"
        if self.yuvname.endswith("__525.yuv"):
            # 525-line sequence -- pad it to 625-line size.
            # XXX For non-interlaced video, we could scale up to 625-line size instead.
            insize = "720x486"
            inrate = "29.97"
            # To keep the right aspect ratio: scale=648:486
            filters = "scale=922:486,pad=928:576:-1:-1"
        subprocess.check_call(["ffmpeg", "-loglevel", "error",
            "-f", "rawvideo", "-pix_fmt", "uyvy422", "-s", insize, "-r", inrate,
            "-i", self.yuvname,
            "-filter:v", filters,
            "-f", "rawvideo", "-pix_fmt", "rgb48", "-s", "928x576", "-y", self.rgbname,
            ])

class LDVTestVideo(TestVideo):
    """A video testcase generated from one of the LDV test sequences produced by SVT.
    These can be downloaded from <https://media.xiph.org/ldv/pub/test_sequences/601/>."""

    # XXX could download into the cache dir automatically
    vqeg_dir = "/n/stuff/tv/Test/ldv"

    def __init__(self, name, yuvname):
        self.yuvname = os.path.join(self.vqeg_dir, yuvname)
        super(LDVTestVideo, self).__init__(name)

    def generate(self):
        subprocess.check_call(["ffmpeg", "-loglevel", "error",
            "-f", "rawvideo", "-pix_fmt", "yuv420p", "-s", "720x576", "-r", "25",
            "-i", self.yuvname,
            "-filter:v", "scale=922:576,pad=928:576:-1:-1",
            "-f", "rawvideo", "-pix_fmt", "rgb48", "-s", "928x576", "-y", self.rgbname,
            ])

def parse_ffmpeg_stats(filename, want_key):
    """Read a stats file from ffmpeg's psnr or ssim filter.
    Return a list of float values with the given key."""

    values = []
    with open(filename) as f:
        for line in f.readlines():
            for field in line.rstrip().split():
                parts = field.split(":", 1)
                if len(parts) == 2 and parts[0] == want_key:
                    values.append(float(parts[1]))
    return values

def evaluate(testcase, decoder_args):
    outprefix = os.path.join(tmp_dir, testcase.name + ".out")

    # Start ld-chroma-decoder with output to a pipe
    outrgbname = outprefix + ".rgb"
    decoder_cmd = [
        os.path.join(lddecode_dir, "tools", "ld-chroma-decoder", "ld-chroma-decoder"),
        "--quiet",
        "--chroma-gain", "1.0",
        ] + decoder_args + [
        testcase.tbcname, # output to stdout
        ]
    decoder_proc = subprocess.Popen(decoder_cmd, stdout=subprocess.PIPE)

    # Start ffmpeg reading from the pipe.
    # Compute PSNR and SSIM between the input and output .rgb files.
    # The values returned may be "inf" if the output is identical to the input...
    psnrname = outprefix + ".psnr"
    ssimname = outprefix + ".ssim"
    ffmpeg_command = [
        "ffmpeg", "-loglevel", "error",
        "-f", "rawvideo", "-pix_fmt", "rgb48", "-s", "928x576", "-i", "-",
        "-f", "rawvideo", "-pix_fmt", "rgb48", "-s", "928x576", "-i", testcase.rgbname,
        "-lavfi", "[0:v][1:v]psnr=stats_file=%s; [0:v][1:v]ssim=stats_file=%s"
            % (psnrname, ssimname),
        "-f", "null", "-",
        ]
    ffmpeg_proc = subprocess.Popen(ffmpeg_command, stdin=decoder_proc.stdout)

    # Wait for the two processes to finish
    rc = decoder_proc.wait()
    if rc != 0:
        raise subprocess.CalledProcessError(rc, decoder_cmd)
    rc = ffmpeg_proc.wait()
    if rc != 0:
        raise subprocess.CalledProcessError(rc, ffmpeg_cmd)

    # Read the per-frame stats back from ffmpeg
    psnrs = parse_ffmpeg_stats(psnrname, "psnr_avg")
    psnr = statistics.mean(psnrs)
    ssims = parse_ffmpeg_stats(ssimname, "All")
    ssim = statistics.mean(ssims)

    return psnr, ssim

testcases = {}
for testcase in [
    LAVTestVideo("lavfi-magenta", "color=c=0xBF00BF"),
    LAVTestVideo("lavfi-testsrc", "testsrc"),
    LAVTestVideo("lavfi-pal75bars", "pal75bars"),

    # Names for these come from frtv_phase1_final_report.doc
    VQEGTestVideo("vqeg-tree", "src1_ref__625.yuv"),
    VQEGTestVideo("vqeg-barcelona", "src2_ref__625.yuv"),
    VQEGTestVideo("vqeg-harp", "src3_ref__625.yuv"),
    VQEGTestVideo("vqeg-movinggraphic", "src4_ref__625.yuv"),
    VQEGTestVideo("vqeg-canoavalsesia", "src5_ref__625.yuv"),
    VQEGTestVideo("vqeg-f1car", "src6_ref__625.yuv"),
    VQEGTestVideo("vqeg-fries", "src7_ref__625.yuv"),
    VQEGTestVideo("vqeg-horizontalscrolling", "src8_ref__625.yuv"),
    VQEGTestVideo("vqeg-rugby", "src9_ref__625.yuv"),
    VQEGTestVideo("vqeg-mobilecalendar", "src10_ref__625.yuv"),
    VQEGTestVideo("vqeg-balloonpops", "src13_ref__525.yuv"),
    VQEGTestVideo("vqeg-newyork", "src14_ref__525.yuv"),
#    VQEGTestVideo("vqeg-mobilecalendar525", "src15_ref__525.yuv"),
    VQEGTestVideo("vqeg-betespasbetes", "src16_ref__525.yuv"),
    VQEGTestVideo("vqeg-lepoint", "src17_ref__525.yuv"),
    VQEGTestVideo("vqeg-autumnleaves", "src18_ref__525.yuv"),
    VQEGTestVideo("vqeg-football", "src19_ref__525.yuv"),
    VQEGTestVideo("vqeg-sailboat", "src20_ref__525.yuv"),
    VQEGTestVideo("vqeg-susie", "src21_ref__525.yuv"),
    VQEGTestVideo("vqeg-tempete", "src22_ref__525.yuv"),

    LDVTestVideo("ldv-mobcal", "576i25_mobcal_ter.yuv"),
    LDVTestVideo("ldv-parkrun", "576i25_parkrun_ter.yuv"),
    LDVTestVideo("ldv-shields", "576i25_shields_ter.yuv"),
    LDVTestVideo("ldv-stockholm", "576i25_stockholm_ter.yuv"),
    ]:
    testcases[testcase.name] = testcase

"""
We represent threshold values 0.0-1.0 as integers from 0-100.

Grid sizes:
transform3d: 8 * 32 * ((16 / 8) + 1) = 768
transform2d: 16 * ((32 / 8) + 1) = 80
"""

# transform2d:
THRESHOLDS_Z = 1
THRESHOLDS_Y = 16
TILE_X = 32
# transform3d:
THRESHOLDS_Z = 8
THRESHOLDS_Y = 32
TILE_X = 16

THRESHOLDS_X = (TILE_X // 8) + 1

def cell(x, y, z):
    return (((z * THRESHOLDS_Y) + y) * THRESHOLDS_X) + x
def clamp_cell(v):
    return max(0, min(100, v))

THRESHOLDS_SIZE = THRESHOLDS_Z * THRESHOLDS_Y * THRESHOLDS_X
QUANTUM = 5
POPULATION_SIZE = 50
# Normally:
NUM_PREVIOUS_RANDOM = 0
# After changing the set of tests:
#NUM_PREVIOUS_RANDOM = POPULATION_SIZE
NUM_CHILDREN = 1
# For experimentation:
#USE_TESTCASES = ["vqeg-mobilecalendar"]
# Small set for initial exploration:
USE_TESTCASES = ["lavfi-pal75bars", "vqeg-mobilecalendar", "vqeg-harp", "ldv-shields", "ldv-stockholm"]
# Complete set:
#USE_TESTCASES = sorted(testcases.keys())

# RNGs for creating random individuals, and making evolutionary choices.
# (The idea being that we cache the results of evaluating individuals, so
# generating the same random individuals saves some effort.)
create_random = random.Random(42)
choose_random = random.Random(73)

# Directory containing a cache of the individuals we've tried so far
hof_dir = os.path.join(cache_dir, "hof3d")
os.makedirs(hof_dir, exist_ok=True)

class Individual:
    def __init__(self, source, arg=None):
        # thresholds are immutable once an Individual is created.

        if source == "constant":
            self.thresholds = THRESHOLDS_SIZE * [arg]
        elif source == "random":
            self.thresholds = [create_random.randint(0, 100 / QUANTUM) * QUANTUM for i in range(THRESHOLDS_SIZE)]
        elif source == "copy":
            self.thresholds = arg
        else:
            raise ValueError("bad source: " + source)

        # Hash the thresholds to generate a unique filename
        self.hash = hashlib.sha256(" ".join(map(str, self.thresholds)).encode("UTF-8")).hexdigest()
        self.thresholds_name = os.path.join(hof_dir, self.hash + ".thresholds")
        self.scores_name = os.path.join(hof_dir, self.hash + ".scores")

        self.scores = None
        self.total_score = None

    def __repr__(self):
        return "[%s]" % (",".join(map(str, self.thresholds)))

    def write_thresholds(self):
        with open(self.thresholds_name + ".new", "w") as f:
            for z in range(THRESHOLDS_Z):
                for y in range(THRESHOLDS_Y):
                    for x in range(THRESHOLDS_X):
                        f.write("%.02f " % (self.thresholds[cell(x, y, z)] * 0.01))
                    f.write("\n")
                f.write("\n")
        os.rename(self.thresholds_name + ".new", self.thresholds_name)

    def read_scores(self):
        self.scores = {}
        try:
            with open(self.scores_name) as f:
                for line in f.readlines():
                    name, score = line.rstrip().split(",")
                    self.scores[name] = float(score)
        except IOError:
            pass

    def update_total(self):
        """Compute the total score as the product of all the scores we're currently using.
        Note this will give different results as the set of testcases changes,
        and it assumes there are scores for all current testcases."""
        self.total_score = 1.0
        for testcase_name in USE_TESTCASES:
            self.total_score *= self.scores[testcase_name]

    def write_scores(self):
        with open(self.scores_name + ".new", "w") as f:
            for name, score in sorted(self.scores.items()):
                f.write("%s,%f\n" % (name, score))
        os.rename(self.scores_name + ".new", self.scores_name)

def load_individual(filename, same_testcases=False):
    if not filename.endswith(".thresholds"):
        return None

    # Load the thresholds, checking they're the right size
    with open(os.path.join(hof_dir, filename)) as f:
        thresholds = [int(float(s) * 100) for s in f.read().rstrip().split()]
    if len(thresholds) != THRESHOLDS_SIZE:
        return None

    # Create the individual
    ind = Individual("copy", thresholds)
    if ind.hash != filename[:-len(".thresholds")]:
        # This shouldn't happen, but if it does (probably due to a leftover
        # file from earlier development), ignore it.
        return None
    ind.read_scores()

    if same_testcases:
        # Check we have scores for all the testcases we're using.
        for testcase_name in USE_TESTCASES:
            if testcase_name not in ind.scores:
                return None

    return ind

def show_stats():
    births = []
    mutations = {}

    for filename in sorted(os.listdir(hof_dir)):
        # We only want individuals with the current set of testcases
        ind = load_individual(filename, same_testcases=True)
        if ind is None:
            continue
        logging.info("reading %s", filename)

        birth = ind.scores.get("_birth")
        firstscore = ind.scores.get("_firstscore")
        parentscore = ind.scores.get("_parentscore")
        mutation = ind.scores.get("_mutation")
        delta = ind.scores.get("_delta", 0)
        radius = ind.scores.get("_radius", 0)

        if birth is not None:
            births.append((birth, ind))

        if (mutation is not None) and (firstscore is not None) and (parentscore is not None):
            mutation = int(mutation)
            delta = int(delta)
            if mutation < 6:
                key = "plane" + ("+%d" % delta if delta > 0 else "%d" % delta)
            elif mutation < 9:
                key = ("radius%d" % radius) + ("+%d" % delta if delta > 0 else "%d" % delta)
            elif mutation == 9:
                key = "crossover"
            elif mutation == 10:
                key = "crossover-radius%d" % radius
            else:
                key = "?"

            counts = mutations.setdefault(key, [0, 0])
            if firstscore > parentscore:
                counts[0] += 1
            counts[1] += 1

    births.sort()

    # Show the series of best results found over time.
    logging.info("writing result_history.png")
    best_inds = [births[0][1]]
    last_time = 0.0
    best_score = 0.0
    for birth, ind in births:
        ind.update_total()

        # It needs to be the best score seen so far...
        if ind.total_score < best_score:
            continue
        best_score = ind.total_score

        # And it needs to be at least 30m after the last one reported.
        if (birth - last_time) < (30 * 60):
            continue
        last_time = birth

        best_inds.append(ind)

    logging.info("%d inds", len(best_inds))
    COMPLEX_X = TILE_X // 2
    img_w = (len(best_inds) * (COMPLEX_X + 1)) + 1
    img_h = ((THRESHOLDS_Y + 1) * THRESHOLDS_Z) + 1
    img = PIL.Image.new("RGB", (img_w, img_h))
    draw = PIL.ImageDraw.Draw(img)
    # Plot to match ld-chroma-decoder's FFT visualisation in layout; the thresholds array
    # covers XTILE/8 <= x <= XTILE/4 (and reflects around XTILE/4)
    off_x = TILE_X // 8
    for i, ind in enumerate(best_inds):
        tl_x = (COMPLEX_X + 1) * i
        for z in range(THRESHOLDS_Z):
            tl_y = (THRESHOLDS_Y + 1) * z
            draw.rectangle([(tl_x, tl_y), (tl_x + COMPLEX_X + 1, tl_y + THRESHOLDS_Y + 1)], outline=0x004000, width=0)
            for y in range(THRESHOLDS_Y):
                for x in range(THRESHOLDS_X):
                    # Invert the value so black = always chroma, white = always luma
                    v = 255 - int((ind.thresholds[cell(x, y, z)] / 100.0) * 255)
                    img.putpixel((tl_x + 1 + x + off_x, tl_y + y + 1), (v << 16) | (v << 8) | v)
                    # And the reflection since the same threshold is used for both:
                    img.putpixel((tl_x + 1 + ((TILE_X // 2) - (x + off_x)), tl_y + y + 1), (v << 16) | (v << 8) | v)
    img.save("result_history.png")

    logging.info("writing births_scores.csv")
    with open("births_scores.csv", "w") as f:
        for birth, ind in births:
            f.write("%f,%f\n" % (birth, ind.total_score))

    logging.info("writing mutations.csv")
    with open("mutations.csv", "w") as f:
        for mutation, counts in sorted(mutations.items()):
            f.write("%s,%d,%d\n" % (mutation, counts[0], counts[1]))

if sys.argv[1:] == ["--stats"]:
    show_stats()
    sys.exit(0)

# Start with a known-fairly-good configuration.
population = [Individual("constant", 45)]

def insert_individual(new_population, ind):
    """Returns True if inserted, False if it was already there."""
    for other in new_population:
        if other.hash == ind.hash:
            return False
    new_population.append(ind)
    return True

# And some that were successfully evolved in the past...
# transform2d:
WINNERS2D = [
    "26ed6bbcbde9cbd3bdc0a1ec486ed577fabf9bf30ba20c2fb6f73af238fc172a.thresholds",
    "cbe73a8e39276df08e30f7a2f5b1cba6ad1851047d4cbadd738e2a959aaa5565.thresholds",
    ]
# transform3d:
WINNERS = []
for filename in WINNERS:
    ind = load_individual(filename)
    if ind is None:
        continue

    logging.info("Using previous winner HoF individual %s", ind.hash)
    insert_individual(population, ind)

# Find previously-saved configurations that have the set of testcases we're
# using, so we implicitly continue from a previous run. The cost of including
# these is minimal because we don't have to run any new tests, so we include
# all of them in the first generation.
# We have to sort here so that the shuffle below is deterministic.
hof_filenames = sorted(os.listdir(hof_dir))
for filename in hof_filenames:
    ind = load_individual(filename, same_testcases=True)
    if ind is None:
        continue

    logging.info("Using complete HoF individual %s", ind.hash)
    insert_individual(population, ind)

# Randomly select at most POPULATION_SIZE previous configurations (that don't
# have a complete set of tests already), for variety. This means you can
# continue with a different set of tests.
choose_random.shuffle(hof_filenames, choose_random.random)
count = 0
for filename in hof_filenames:
    if count >= NUM_PREVIOUS_RANDOM:
        break

    ind = load_individual(filename)
    if ind is None:
        continue

    if insert_individual(population, ind):
        logging.info("Using random HoF individual %s", ind.hash)
        count += 1

generation = 0
while True:
    logging.info("-" * 70)
    logging.info("Generation %d, population %d", generation, len(population))

    # Read in existing scores
    for ind in population:
        ind.read_scores()

    # Evaluate all the individuals against all the testcases.
    # Since the testcase data is large (several gigabytes), evaluate all
    # individuals against each testcase before moving on to the next testcase.
    for testcase_name in USE_TESTCASES:
        logging.info("Evaluating with %s", testcase_name)
        testcase = testcases[testcase_name]

        for ind in population:
            if testcase_name in ind.scores:
                #logging.info("Already done individual %s - score %f", ind.hash, ind.scores[testcase_name])
                continue

            ind.write_thresholds()
            decoder_args = ["-f", "transform3d", "--transform-thresholds", ind.thresholds_name]
            psnr, ssim = evaluate(testcase, decoder_args)
            logging.info("Testcase %s individual %s PSNR %f SSIM %f", testcase_name, ind.hash, psnr, ssim)

            ind.scores[testcase_name] = ssim
            ind.write_scores()

    # Periodically resurrect a set of random older individuals for variety
    is_resurrection = (generation % 50) == 0
    resurrected = []
    if is_resurrection:
        hof_filenames = os.listdir(hof_dir)
        choose_random.shuffle(hof_filenames, choose_random.random)
        for filename in hof_filenames:
            ind = load_individual(filename, same_testcases=True)
            if ind is None:
                continue

            insert_individual(resurrected, ind)
            if len(resurrected) >= POPULATION_SIZE:
                break

    # Update total scores
    for ind in population + resurrected:
        ind.update_total()

        # Record total score if this is the first time we've done it
        if "_firstscore" not in ind.scores:
            # XXX Hack because I introduced this partway through a run
            if "_birth" not in ind.scores:
                ind.scores["_birth"] = os.stat(ind.scores_name).st_mtime

            ind.scores["_firstscore"] = ind.total_score
            ind.write_scores()

    # Sort the best individuals first and trim to max size
    population.sort(key=lambda ind: -ind.total_score)
    population = population[:POPULATION_SIZE]

    # Add in the resurrected individuals
    if is_resurrection:
        for ind in resurrected:
            if insert_individual(population, ind):
                logging.info("resurrecting %s", ind.hash)
        population.sort(key=lambda ind: -ind.total_score)

    # Show stats
    logging.info("Generation %d leaderboard:", generation)
    for ind in population:
        logging.info("- %s - total_score %f", ind.hash, ind.total_score)
    total_scores = [ind.total_score for ind in population]
    logging.info("Generation %d: median score %f, best score %f", generation,
                 statistics.median(total_scores), max(total_scores))

    # Generate new children
    new_population = population[:]
    want_children = POPULATION_SIZE if is_resurrection else NUM_CHILDREN
    while len(new_population) < len(population) + want_children:

        # Choose a parent -- usually the best one
        # XXX This is more an SA than GA approach...
        if choose_random.random() < 0.8:
            parent = population[0]
        else:
            parent = choose_random.choice(population)
        logging.info("child mutating from %s", parent.hash)

        # Mutate
        # XXX These are all conservative changes -- it may be better to have a "set
        # to random" mutation to avoid getting stuck in a local maximum. (But that
        # may not be a problem depending on what the search space looks like...)
        thresholds = parent.thresholds[:]
        mutation = choose_random.choice([0, 6, 6, 6, 9, 10])
        if is_resurrection:
            mutation = 10
        delta = 0
        radius = 0
        if mutation == 0:
            # Raise/lower plane

            want_x, want_y, want_z = -1, -1, -1
            delta = QUANTUM * choose_random.choice([-1, 1])
            axis = choose_random.randrange(3)
            if axis == 0:
                want_x = choose_random.randrange(THRESHOLDS_X)
            elif axis == 1:
                want_y = choose_random.randrange(THRESHOLDS_Y)
            elif axis == 2:
                want_z = choose_random.randrange(THRESHOLDS_Z)
            logging.info("raise plane %d,%d,%d by %d", want_x, want_y, want_z, delta)

            for z in range(THRESHOLDS_Z):
                if want_z != -1 and want_z != z:
                    continue
                for y in range(THRESHOLDS_Y):
                    if want_y != -1 and want_y != y:
                        continue
                    for x in range(THRESHOLDS_X):
                        if want_x != -1 and want_x != x:
                            continue
                        idx = cell(x, y, z)
                        thresholds[idx] = clamp_cell(thresholds[idx] + delta)

        elif mutation == 6:
            # Raise/lower radius

            delta = QUANTUM * choose_random.choice([-3, -2, -2, -1, -1, -1, 1, 1, 1, 2, 2, 3])
            cx = choose_random.randrange(THRESHOLDS_X)
            cy = choose_random.randrange(THRESHOLDS_Y)
            cz = choose_random.randrange(THRESHOLDS_Z)
            radius = choose_random.randrange(min(THRESHOLDS_X, THRESHOLDS_Y, THRESHOLDS_Z))
            logging.info("raise radius %d around %d,%d,%d by %d", radius, cx, cy, cz, delta)

            r2 = radius * radius
            for z in range(THRESHOLDS_Z):
                for y in range(THRESHOLDS_Y):
                    for x in range(THRESHOLDS_X):
                        if ((cy - y) * (cy - y)) + ((cx - x) * (cx - x)) + ((cz - z) * (cz - z)) < r2:
                            idx = cell(x, y, z)
                            thresholds[idx] = clamp_cell(thresholds[idx] + delta)

        elif mutation == 9:
            # Plane crossover

            # Select a second parent
            parent2 = parent
            if len(population) > 1:
                while parent.hash == parent2.hash:
                    parent2 = choose_random.choice(population)
            if choose_random.random() > 0.5:
                parent, parent2 = parent2, parent

            # Select a random plane
            x_split, y_split, z_split = 0, 0, 0
            axis = choose_random.randrange(3)
            if axis == 0:
                x_split = choose_random.randint(1, THRESHOLDS_X - 1)
            elif axis == 1:
                y_split = choose_random.randint(1, THRESHOLDS_Y - 1)
            elif axis == 2:
                z_split = choose_random.randint(1, THRESHOLDS_Z - 1)

            logging.info("crossover between %s and %s at %d,%d,%d", parent.hash, parent2.hash, x_split, y_split, z_split)

            # Join the two halves together
            for z in range(THRESHOLDS_Z):
                for y in range(THRESHOLDS_Y):
                    for x in range(THRESHOLDS_X):
                        idx = cell(x, y, z)
                        if x >= x_split and y >= y_split and z >= z_split:
                            thresholds[idx] = parent.thresholds[idx]
                        else:
                            thresholds[idx] = parent2.thresholds[idx]

        elif mutation == 10:
            # Radius crossover

            # Select a second parent
            parent2 = parent
            if len(population) > 1:
                while parent.hash == parent2.hash:
                    parent2 = choose_random.choice(population)

            # Select a radius
            cx = choose_random.randrange(THRESHOLDS_X)
            cy = choose_random.randrange(THRESHOLDS_Y)
            cz = choose_random.randrange(THRESHOLDS_Z)
            radius = choose_random.randrange((THRESHOLDS_X + THRESHOLDS_Y + THRESHOLDS_Z) // 3)

            logging.info("crossover-radius between %s and %s around %d,%d,%d radius %d",
                         parent.hash, parent2.hash, cx, cy, cz, radius)

            # Insert the patch from parent2
            r2 = radius * radius
            for z in range(THRESHOLDS_Z):
                for y in range(THRESHOLDS_Y):
                    for x in range(THRESHOLDS_X):
                        idx = cell(x, y, z)
                        if ((cy - y) * (cy - y)) + ((cx - x) * (cx - x)) + ((cz - z) * (cz - z)) < r2:
                            thresholds[idx] = parent2.thresholds[idx]

        else:
            raise ValueError("unknown mutation %d" % mutation)

        # Insert the new child, if it doesn't duplicate one we already have
        child = Individual("copy", thresholds)
        insert_individual(new_population, child)

        # Record information about the child's creation, for later stats
        child.read_scores()
        if "_birth" not in child.scores:
            child.scores["_birth"] = time.time()
            child.scores["_parentscore"] = parent.total_score
            child.scores["_bestscore"] = population[0].total_score
            child.scores["_mutation"] = float(mutation)
            child.scores["_delta"] = delta
            child.scores["_radius"] = radius
            child.write_scores()

    population = new_population
    generation += 1
