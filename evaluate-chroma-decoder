#!/usr/bin/python3
# Evaluate the performance of ld-chroma-decoder by encoding test material.

# XXX There's a lot of duplication between the ffmpeg commands...
# XXX Output stats as a .csv?

import hashlib
import logging
import os
import random
import statistics
import subprocess
import sys

logging.basicConfig(level=logging.INFO)

testsuite_dir = os.path.realpath(os.path.dirname(sys.argv[0]))
lddecode_dir = os.path.join(testsuite_dir, "..", "ld-decode")

cache_dir = os.path.join(testsuite_dir, "cache", "evaluate")
os.makedirs(cache_dir, exist_ok=True)

tmp_dir = "/var/tmp/lddtest/evaluate"
os.makedirs(tmp_dir, exist_ok=True)

class TestVideo:
    """A video testcase."""

    def __init__(self, name):
        self.name = name

        self.rgbname = os.path.join(cache_dir, name + ".rgb")
        if not os.path.exists(self.rgbname):
            logging.info("Generating %s", self.rgbname)
            self.generate()

        self.tbcname = os.path.join(cache_dir, name + ".tbc")
        if not os.path.exists(self.tbcname):
            logging.info("Encoding %s", self.tbcname)
            self.encode()

    def generate(self):
        """Generate the .rgb through whatever mechanism.
        Subclasses should override this."""

        raise NotImplementedError("generate")

    def encode(self):
        """Encode the .rgb into a .tbc."""

        # XXX assumes PAL
        subprocess.check_call([
            os.path.join(lddecode_dir, "tools", "ld-chroma-decoder", "encoder", "ld-chroma-encoder"),
            self.rgbname, self.tbcname,
            ])

class LAVTestVideo(TestVideo):
    """A video testcase generated from a libavfilter test source."""

    def __init__(self, name, source):
        self.source = source
        if "=" in source:
            self.source += ":"
        else:
            self.source += "="
        self.source += "duration=1:size=922x576:rate=25"
        super(LAVTestVideo, self).__init__(name)

    def generate(self):
        subprocess.check_call(["ffmpeg", "-loglevel", "error",
            "-f", "lavfi", "-i", self.source,
            "-filter:v", "pad=928:576:-1:-1",
            "-f", "rawvideo", "-pix_fmt", "rgb48", "-s", "928x576", "-y", self.rgbname,
            ])

class VQEGTestVideo(TestVideo):
    """A video testcase generated from one of the VQEG test sequences.
    These can be downloaded from <https://media.xiph.org/vqeg/TestSequences/>."""

    # XXX could download into the cache dir automatically
    vqeg_dir = "/n/stuff/tv/Test/vqeg"

    def __init__(self, name, yuvname):
        self.yuvname = os.path.join(self.vqeg_dir, yuvname)
        super(VQEGTestVideo, self).__init__(name)

    def generate(self):
        insize = "720x576"
        inrate = "25"
        filters = "scale=922:576,pad=928:576:-1:-1"
        if self.yuvname.endswith("__525.yuv"):
            # 525-line sequence -- pad it to 625-line size.
            # XXX For non-interlaced video, we could scale up to 625-line size instead.
            insize = "720x486"
            inrate = "29.97"
            filters = "scale=648:486,pad=928:576:-1:-1"
        subprocess.check_call(["ffmpeg", "-loglevel", "error",
            "-f", "rawvideo", "-pix_fmt", "uyvy422", "-s", insize, "-r", inrate,
            "-i", self.yuvname,
            "-filter:v", filters,
            "-f", "rawvideo", "-pix_fmt", "rgb48", "-s", "928x576", "-y", self.rgbname,
            ])

class LDVTestVideo(TestVideo):
    """A video testcase generated from one of the LDV test sequences produced by SVT.
    These can be downloaded from <https://media.xiph.org/ldv/pub/test_sequences/601/>."""

    # XXX could download into the cache dir automatically
    vqeg_dir = "/n/stuff/tv/Test/ldv"

    def __init__(self, name, yuvname):
        self.yuvname = os.path.join(self.vqeg_dir, yuvname)
        super(LDVTestVideo, self).__init__(name)

    def generate(self):
        subprocess.check_call(["ffmpeg", "-loglevel", "error",
            "-f", "rawvideo", "-pix_fmt", "yuv420p", "-s", "720x576", "-r", "25",
            "-i", self.yuvname,
            "-filter:v", "scale=922:576,pad=928:576:-1:-1",
            "-f", "rawvideo", "-pix_fmt", "rgb48", "-s", "928x576", "-y", self.rgbname,
            ])

def parse_ffmpeg_stats(filename, want_key):
    """Read a stats file from ffmpeg's psnr or ssim filter.
    Return a list of float values with the given key."""

    values = []
    with open(filename) as f:
        for line in f.readlines():
            for field in line.rstrip().split():
                parts = field.split(":", 1)
                if len(parts) == 2 and parts[0] == want_key:
                    values.append(float(parts[1]))
    return values

def evaluate(testcase, decoder_args):
    outprefix = os.path.join(tmp_dir, testcase.name + ".out")

    # Run ld-chroma-decoder
    outrgbname = outprefix + ".rgb"
    cmd = [os.path.join(lddecode_dir, "tools", "ld-chroma-decoder", "ld-chroma-decoder")]
    cmd += ["--quiet", "--chroma-gain", "1.0"]
    cmd += decoder_args
    cmd += [testcase.tbcname, outrgbname]
    subprocess.check_call(cmd)

    # Compute PSNR and SSIM between the input and output .rgb files.
    # The values returned may be "inf" if the output is identical to the input...
    psnrname = outprefix + ".psnr"
    ssimname = outprefix + ".ssim"
    subprocess.check_call(["ffmpeg", "-loglevel", "error",
        "-f", "rawvideo", "-pix_fmt", "rgb48", "-s", "928x576", "-i", outrgbname,
        "-f", "rawvideo", "-pix_fmt", "rgb48", "-s", "928x576", "-i", testcase.rgbname,
        "-lavfi", "[0:v][1:v]psnr=stats_file=%s; [0:v][1:v]ssim=stats_file=%s"
            % (psnrname, ssimname),
        "-f", "null", "-",
        ])

    # Read the per-frame stats back from ffmpeg
    psnrs = parse_ffmpeg_stats(psnrname, "psnr_avg")
    psnr = statistics.mean(psnrs)
    ssims = parse_ffmpeg_stats(ssimname, "All")
    ssim = statistics.mean(ssims)

    return psnr, ssim

testcases = {}
for testcase in [
    LAVTestVideo("lavfi-magenta", "color=c=0xBF00BF"),
    LAVTestVideo("lavfi-testsrc", "testsrc"),
    LAVTestVideo("lavfi-pal75bars", "pal75bars"),

    # Names for these come from frtv_phase1_final_report.doc
    VQEGTestVideo("vqeg-tree", "src1_ref__625.yuv"),
    VQEGTestVideo("vqeg-barcelona", "src2_ref__625.yuv"),
    VQEGTestVideo("vqeg-harp", "src3_ref__625.yuv"),
    VQEGTestVideo("vqeg-movinggraphic", "src4_ref__625.yuv"),
    VQEGTestVideo("vqeg-canoavalsesia", "src5_ref__625.yuv"),
    VQEGTestVideo("vqeg-f1car", "src6_ref__625.yuv"),
    VQEGTestVideo("vqeg-fries", "src7_ref__625.yuv"),
    VQEGTestVideo("vqeg-horizontalscrolling", "src8_ref__625.yuv"),
    VQEGTestVideo("vqeg-rugby", "src9_ref__625.yuv"),
    VQEGTestVideo("vqeg-mobilecalendar", "src10_ref__625.yuv"),
    VQEGTestVideo("vqeg-balloonpops", "src13_ref__525.yuv"),
    VQEGTestVideo("vqeg-newyork", "src14_ref__525.yuv"),
    VQEGTestVideo("vqeg-mobilecalendar525", "src15_ref__525.yuv"),
    VQEGTestVideo("vqeg-betespasbetes", "src16_ref__525.yuv"),
    VQEGTestVideo("vqeg-lepoint", "src17_ref__525.yuv"),
    VQEGTestVideo("vqeg-autumnleaves", "src18_ref__525.yuv"),
    VQEGTestVideo("vqeg-football", "src19_ref__525.yuv"),
    VQEGTestVideo("vqeg-sailboat", "src20_ref__525.yuv"),
    VQEGTestVideo("vqeg-susie", "src21_ref__525.yuv"),
    VQEGTestVideo("vqeg-tempete", "src22_ref__525.yuv"),

    LDVTestVideo("ldv-mobcal", "576i25_mobcal_ter.yuv"),
    LDVTestVideo("ldv-parkrun", "576i25_parkrun_ter.yuv"),
    LDVTestVideo("ldv-shields", "576i25_shields_ter.yuv"),
    LDVTestVideo("ldv-stockholm", "576i25_stockholm_ter.yuv"),
    ]:
    testcases[testcase.name] = testcase

"""
transform3d: 8 * 32 * ((16 / 8) + 1) = 768
transform2d: 16 * ((32 / 8) + 1) = 80

We represent threshold values 0.0-1.0 as integers from 0-100.
"""
THRESHOLDS_Y = 16
THRESHOLDS_X = (32 // 8) + 1
THRESHOLDS_SIZE = THRESHOLDS_Y * THRESHOLDS_X
QUANTUM = 5
POPULATION_SIZE = 40
USE_TESTCASES = ["lavfi-pal75bars", "vqeg-mobilecalendar", "vqeg-harp", "ldv-shields", "ldv-stockholm"]
#USE_TESTCASES = ["vqeg-mobilecalendar"]

# RNGs for creating random individuals, and making evolutionary choices.
# (The idea being that we cache the results of evaluating individuals, so
# generating the same random individuals saves some effort.)
create_random = random.Random(42)
choose_random = random.Random(73)

# Directory containing a cache of the individuals we've tried so far
hof_dir = os.path.join(cache_dir, "hof")
os.makedirs(hof_dir, exist_ok=True)

class Individual:
    def __init__(self, source, arg=None):
        if source == "constant":
            self.thresholds = THRESHOLDS_SIZE * [arg]
        elif source == "random":
            self.thresholds = [create_random.randint(0, 100 / QUANTUM) * QUANTUM for i in range(THRESHOLDS_SIZE)]
        elif source == "copy":
            self.thresholds = arg
        else:
            raise ValueError("bad source: " + source)

        self.hash = hashlib.sha256(" ".join(map(str, self.thresholds)).encode("UTF-8")).hexdigest()
        self.thresholds_name = os.path.join(hof_dir, self.hash + ".thresholds")
        self.scores_name = os.path.join(hof_dir, self.hash + ".scores")

        self.scores = None
        self.total_score = None

    def __repr__(self):
        return "[%s]" % (",".join(map(str, self.thresholds)))

    def write_thresholds(self):
        with open(self.thresholds_name, "w") as f:
            i = 0
            for y in range(THRESHOLDS_Y):
                for x in range(THRESHOLDS_X):
                    f.write("%.02f " % (self.thresholds[i] * 0.01))
                    i += 1
                f.write("\n")
            assert i == THRESHOLDS_SIZE

    def read_scores(self):
        self.scores = {}
        try:
            with open(self.scores_name) as f:
                for line in f.readlines():
                    name, score = line.rstrip().split(",")
                    self.scores[name] = float(score)
        except IOError:
            pass

    def write_scores(self):
        with open(self.scores_name + ".new", "w") as f:
            for name, score in sorted(self.scores.items()):
                f.write("%s,%f\n" % (name, score))
        os.rename(self.scores_name + ".new", self.scores_name)

population = []

# Construct initial population
for i in range(0, 101, QUANTUM):
    population.append(Individual("constant", i))
# XXX Not sure it's worth having random individuals
#while len(population) < POPULATION_SIZE:
#    population.append(Individual("random"))

generation = 0
while True:
    logging.info("-" * 70)
    logging.info("Generation %d, population %d", generation, len(population))

    # Read in state and write out thresholds files
    for ind in population:
        ind.write_thresholds()
        ind.read_scores()

    # Evaluate all the individuals against all the testcases.
    # Since the testcase data is large (several gigabytes), evaluate all
    # individuals against each testcase before moving on to the next testcase.
    for testcase_name in USE_TESTCASES:
        logging.info("Evaluating with %s", testcase_name)
        testcase = testcases[testcase_name]

        for ind in population:
            if testcase_name in ind.scores:
                logging.info("Already done individual %s - score %f", ind.hash, ind.scores[testcase_name])
                continue

            decoder_args = ["-f", "transform2d", "--transform-thresholds", ind.thresholds_name]
            psnr, ssim = evaluate(testcase, decoder_args)
            logging.info("Testcase %s individual %s PSNR %f SSIM %f", testcase_name, ind.hash, psnr, ssim)

            ind.scores[testcase_name] = ssim
            ind.write_scores()

    # Compute total score as the product of all scores we're using
    for ind in population:
        ind.total_score = 1.0
        for testcase_name in USE_TESTCASES:
            ind.total_score *= ind.scores[testcase_name]

    # Sort the best individuals first
    population.sort(key=lambda ind: -ind.total_score)

    # Show stats
    for ind in population:
        logging.info("Individual %s total_score %f", ind.hash, ind.total_score)
    total_scores = [ind.total_score for ind in population]
    logging.info("Generation %d: median score %f, best score %f", generation,
                 statistics.median(total_scores), max(total_scores))

    # Build the new generation.
    # Elitist selection: keep the top 20% as is.
    new_population = population[:POPULATION_SIZE // 5]

    # Add another 10% of random individuals
    # XXX disabled
    #for i in range(POPULATION_SIZE // 10):
    #    new_population.append(Individual("random"))

    # Generate the rest with crossover and mutation
    while len(new_population) < POPULATION_SIZE:
        if choose_random.random() > 0.5:
            # Crossover

            # Select two parents, weighted by score
            parents = choose_random.choices(population, total_scores, k=2)

            # Generate new thresholds by crossover, along a random line on the X or Y axis
            x_split = 0
            y_split = 0
            axis = choose_random.randrange(2)
            if axis == 0:
                x_split = choose_random.randint(1, THRESHOLDS_X - 1)
            elif axis == 1:
                y_split = choose_random.randint(1, THRESHOLDS_Y - 1)

            thresholds = []
            for y in range(THRESHOLDS_Y):
                for x in range(THRESHOLDS_X):
                    idx = (y * THRESHOLDS_X) + x
                    n = 0 if (x >= x_split and y >= y_split) else 1
                    thresholds.append(parents[n].thresholds[idx])
        else:
            # Mutation

            parent = choose_random.choices(population, total_scores, k=1)[0]
            thresholds = parent.thresholds[:]

            pos = choose_random.randrange(THRESHOLDS_SIZE)
            if choose_random.random() > 0.25:
                value = choose_random.choice([QUANTUM, -QUANTUM])
                thresholds[pos] += value
            else:
                thresholds[pos] = create_random.randint(0, 100 / QUANTUM) * QUANTUM

            if thresholds[pos] < 0:
                thresholds[pos] = 0
            elif thresholds[pos] > 100:
                thresholds[pos] = 100

        # Insert the new child, if it doesn't duplicate one we already have
        child = Individual("copy", thresholds)
        for other in new_population:
            if other.hash == child.hash:
                break
        else:
            new_population.append(child)

    population = new_population
    generation += 1
