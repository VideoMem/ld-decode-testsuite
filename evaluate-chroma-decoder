#!/usr/bin/python3
# Optimise filter configurations for ld-chroma-decoder using a genetic
# algorithm. Performance is evaluated by encoding test material with
# ld-chroma-encoder and measuring the similarity of the decoded result using
# SSIM.

# XXX There's a lot of duplication between the ffmpeg commands...
# XXX Output stats as a .csv?
# XXX Try generating an NTSC 3D FFT filter

import hashlib
import logging
import os
import random
import statistics
import subprocess
import sys

logging.basicConfig(level=logging.INFO)

testsuite_dir = os.path.realpath(os.path.dirname(sys.argv[0]))
lddecode_dir = os.path.join(testsuite_dir, "..", "ld-decode")

cache_dir = os.path.join(testsuite_dir, "cache", "evaluate")
os.makedirs(cache_dir, exist_ok=True)

tmp_dir = "/var/tmp/lddtest/evaluate"
os.makedirs(tmp_dir, exist_ok=True)

class TestVideo:
    """A video testcase."""

    def __init__(self, name):
        self.name = name

        self.rgbname = os.path.join(cache_dir, name + ".rgb")
        if not os.path.exists(self.rgbname):
            logging.info("Generating %s", self.rgbname)
            self.generate()

        self.tbcname = os.path.join(cache_dir, name + ".tbc")
        if not os.path.exists(self.tbcname):
            logging.info("Encoding %s", self.tbcname)
            self.encode()

    def generate(self):
        """Generate the .rgb through whatever mechanism.
        Subclasses should override this."""

        raise NotImplementedError("generate")

    def encode(self):
        """Encode the .rgb into a .tbc."""

        # XXX assumes PAL
        subprocess.check_call([
            os.path.join(lddecode_dir, "tools", "ld-chroma-decoder", "encoder", "ld-chroma-encoder"),
            self.rgbname, self.tbcname,
            ])

class LAVTestVideo(TestVideo):
    """A video testcase generated from a libavfilter test source."""

    def __init__(self, name, source):
        self.source = source
        if "=" in source:
            self.source += ":"
        else:
            self.source += "="
        self.source += "duration=1:size=922x576:rate=25"
        super(LAVTestVideo, self).__init__(name)

    def generate(self):
        subprocess.check_call(["ffmpeg", "-loglevel", "error",
            "-f", "lavfi", "-i", self.source,
            "-filter:v", "pad=928:576:-1:-1",
            "-f", "rawvideo", "-pix_fmt", "rgb48", "-s", "928x576", "-y", self.rgbname,
            ])

class VQEGTestVideo(TestVideo):
    """A video testcase generated from one of the VQEG test sequences.
    These can be downloaded from <https://media.xiph.org/vqeg/TestSequences/>."""

    # XXX could download into the cache dir automatically
    vqeg_dir = "/n/stuff/tv/Test/vqeg"

    def __init__(self, name, yuvname):
        self.yuvname = os.path.join(self.vqeg_dir, yuvname)
        super(VQEGTestVideo, self).__init__(name)

    def generate(self):
        insize = "720x576"
        inrate = "25"
        filters = "scale=922:576,pad=928:576:-1:-1"
        if self.yuvname.endswith("__525.yuv"):
            # 525-line sequence -- pad it to 625-line size.
            # XXX For non-interlaced video, we could scale up to 625-line size instead.
            insize = "720x486"
            inrate = "29.97"
            filters = "scale=648:486,pad=928:576:-1:-1"
        subprocess.check_call(["ffmpeg", "-loglevel", "error",
            "-f", "rawvideo", "-pix_fmt", "uyvy422", "-s", insize, "-r", inrate,
            "-i", self.yuvname,
            "-filter:v", filters,
            "-f", "rawvideo", "-pix_fmt", "rgb48", "-s", "928x576", "-y", self.rgbname,
            ])

class LDVTestVideo(TestVideo):
    """A video testcase generated from one of the LDV test sequences produced by SVT.
    These can be downloaded from <https://media.xiph.org/ldv/pub/test_sequences/601/>."""

    # XXX could download into the cache dir automatically
    vqeg_dir = "/n/stuff/tv/Test/ldv"

    def __init__(self, name, yuvname):
        self.yuvname = os.path.join(self.vqeg_dir, yuvname)
        super(LDVTestVideo, self).__init__(name)

    def generate(self):
        subprocess.check_call(["ffmpeg", "-loglevel", "error",
            "-f", "rawvideo", "-pix_fmt", "yuv420p", "-s", "720x576", "-r", "25",
            "-i", self.yuvname,
            "-filter:v", "scale=922:576,pad=928:576:-1:-1",
            "-f", "rawvideo", "-pix_fmt", "rgb48", "-s", "928x576", "-y", self.rgbname,
            ])

def parse_ffmpeg_stats(filename, want_key):
    """Read a stats file from ffmpeg's psnr or ssim filter.
    Return a list of float values with the given key."""

    values = []
    with open(filename) as f:
        for line in f.readlines():
            for field in line.rstrip().split():
                parts = field.split(":", 1)
                if len(parts) == 2 and parts[0] == want_key:
                    values.append(float(parts[1]))
    return values

def evaluate(testcase, decoder_args):
    outprefix = os.path.join(tmp_dir, testcase.name + ".out")

    # Run ld-chroma-decoder
    outrgbname = outprefix + ".rgb"
    cmd = [os.path.join(lddecode_dir, "tools", "ld-chroma-decoder", "ld-chroma-decoder")]
    cmd += ["--quiet", "--chroma-gain", "1.0"]
    cmd += decoder_args
    cmd += [testcase.tbcname, outrgbname]
    subprocess.check_call(cmd)

    # Compute PSNR and SSIM between the input and output .rgb files.
    # The values returned may be "inf" if the output is identical to the input...
    psnrname = outprefix + ".psnr"
    ssimname = outprefix + ".ssim"
    subprocess.check_call(["ffmpeg", "-loglevel", "error",
        "-f", "rawvideo", "-pix_fmt", "rgb48", "-s", "928x576", "-i", outrgbname,
        "-f", "rawvideo", "-pix_fmt", "rgb48", "-s", "928x576", "-i", testcase.rgbname,
        "-lavfi", "[0:v][1:v]psnr=stats_file=%s; [0:v][1:v]ssim=stats_file=%s"
            % (psnrname, ssimname),
        "-f", "null", "-",
        ])

    # Read the per-frame stats back from ffmpeg
    psnrs = parse_ffmpeg_stats(psnrname, "psnr_avg")
    psnr = statistics.mean(psnrs)
    ssims = parse_ffmpeg_stats(ssimname, "All")
    ssim = statistics.mean(ssims)

    return psnr, ssim

testcases = {}
for testcase in [
    LAVTestVideo("lavfi-magenta", "color=c=0xBF00BF"),
    LAVTestVideo("lavfi-testsrc", "testsrc"),
    LAVTestVideo("lavfi-pal75bars", "pal75bars"),

    # Names for these come from frtv_phase1_final_report.doc
    VQEGTestVideo("vqeg-tree", "src1_ref__625.yuv"),
    VQEGTestVideo("vqeg-barcelona", "src2_ref__625.yuv"),
    VQEGTestVideo("vqeg-harp", "src3_ref__625.yuv"),
    VQEGTestVideo("vqeg-movinggraphic", "src4_ref__625.yuv"),
    VQEGTestVideo("vqeg-canoavalsesia", "src5_ref__625.yuv"),
    VQEGTestVideo("vqeg-f1car", "src6_ref__625.yuv"),
    VQEGTestVideo("vqeg-fries", "src7_ref__625.yuv"),
    VQEGTestVideo("vqeg-horizontalscrolling", "src8_ref__625.yuv"),
    VQEGTestVideo("vqeg-rugby", "src9_ref__625.yuv"),
    VQEGTestVideo("vqeg-mobilecalendar", "src10_ref__625.yuv"),
    VQEGTestVideo("vqeg-balloonpops", "src13_ref__525.yuv"),
    VQEGTestVideo("vqeg-newyork", "src14_ref__525.yuv"),
    VQEGTestVideo("vqeg-mobilecalendar525", "src15_ref__525.yuv"),
    VQEGTestVideo("vqeg-betespasbetes", "src16_ref__525.yuv"),
    VQEGTestVideo("vqeg-lepoint", "src17_ref__525.yuv"),
    VQEGTestVideo("vqeg-autumnleaves", "src18_ref__525.yuv"),
    VQEGTestVideo("vqeg-football", "src19_ref__525.yuv"),
    VQEGTestVideo("vqeg-sailboat", "src20_ref__525.yuv"),
    VQEGTestVideo("vqeg-susie", "src21_ref__525.yuv"),
    VQEGTestVideo("vqeg-tempete", "src22_ref__525.yuv"),

    LDVTestVideo("ldv-mobcal", "576i25_mobcal_ter.yuv"),
    LDVTestVideo("ldv-parkrun", "576i25_parkrun_ter.yuv"),
    LDVTestVideo("ldv-shields", "576i25_shields_ter.yuv"),
    LDVTestVideo("ldv-stockholm", "576i25_stockholm_ter.yuv"),
    ]:
    testcases[testcase.name] = testcase

"""
We represent threshold values 0.0-1.0 as integers from 0-100.

Grid sizes:
transform3d: 8 * 32 * ((16 / 8) + 1) = 768
transform2d: 16 * ((32 / 8) + 1) = 80
"""
THRESHOLDS_Y = 16
THRESHOLDS_X = (32 // 8) + 1
THRESHOLDS_SIZE = THRESHOLDS_Y * THRESHOLDS_X
QUANTUM = 5
POPULATION_SIZE = 20
NUM_CHILDREN = 1
USE_TESTCASES = ["lavfi-pal75bars", "vqeg-mobilecalendar", "vqeg-harp", "ldv-shields", "ldv-stockholm"]
#USE_TESTCASES = ["vqeg-mobilecalendar"]

# RNGs for creating random individuals, and making evolutionary choices.
# (The idea being that we cache the results of evaluating individuals, so
# generating the same random individuals saves some effort.)
create_random = random.Random(42)
choose_random = random.Random(73)

# Directory containing a cache of the individuals we've tried so far
hof_dir = os.path.join(cache_dir, "hof")
os.makedirs(hof_dir, exist_ok=True)

class Individual:
    def __init__(self, source, arg=None):
        # thresholds are immutable once an Individual is created.

        if source == "constant":
            self.thresholds = THRESHOLDS_SIZE * [arg]
        elif source == "random":
            self.thresholds = [create_random.randint(0, 100 / QUANTUM) * QUANTUM for i in range(THRESHOLDS_SIZE)]
        elif source == "copy":
            self.thresholds = arg
        else:
            raise ValueError("bad source: " + source)

        # Hash the thresholds to generate a unique filename
        self.hash = hashlib.sha256(" ".join(map(str, self.thresholds)).encode("UTF-8")).hexdigest()
        self.thresholds_name = os.path.join(hof_dir, self.hash + ".thresholds")
        self.scores_name = os.path.join(hof_dir, self.hash + ".scores")

        self.scores = None
        self.total_score = None

    def __repr__(self):
        return "[%s]" % (",".join(map(str, self.thresholds)))

    def write_thresholds(self):
        with open(self.thresholds_name + ".new", "w") as f:
            i = 0
            for y in range(THRESHOLDS_Y):
                for x in range(THRESHOLDS_X):
                    f.write("%.02f " % (self.thresholds[i] * 0.01))
                    i += 1
                f.write("\n")
            assert i == THRESHOLDS_SIZE
        os.rename(self.thresholds_name + ".new", self.thresholds_name)

    def read_scores(self):
        self.scores = {}
        try:
            with open(self.scores_name) as f:
                for line in f.readlines():
                    name, score = line.rstrip().split(",")
                    self.scores[name] = float(score)
        except IOError:
            pass

    def write_scores(self):
        with open(self.scores_name + ".new", "w") as f:
            for name, score in sorted(self.scores.items()):
                f.write("%s,%f\n" % (name, score))
        os.rename(self.scores_name + ".new", self.scores_name)

# Start with a known-fairly-good configuration.
population = [Individual("constant", 45)]

# Find previously-saved configurations that have the set of testcases we're
# using, so we implicitly continue from a previous run.
for filename in os.listdir(hof_dir):
    if not filename.endswith(".thresholds"):
        continue

    # Load the thresholds, checking they're the right size
    with open(os.path.join(hof_dir, filename)) as f:
        thresholds = [int(float(s) * 100) for s in f.read().rstrip().split()]
    if len(thresholds) != THRESHOLDS_SIZE:
        continue

    # Create the individual
    ind = Individual("copy", thresholds)
    if ind.hash != filename[:-len(".thresholds")]:
        # This shouldn't happen, but if it does (probably due to a leftover
        # file from earlier development), ignore it.
        continue
    ind.read_scores()

    # Check we have scores for all the testcases we're using.
    # XXX Could make a guess if it has some of them, to avoid redoing
    # everything from scratch when adding a new testcase...
    for testcase_name in USE_TESTCASES:
        if testcase_name not in ind.scores:
            break
    else:
        logging.info("Using HoF individual %s", ind.hash)
        population.append(ind)

generation = 0
while True:
    logging.info("-" * 70)
    logging.info("Generation %d, population %d", generation, len(population))

    # Read in existing scores
    for ind in population:
        ind.read_scores()

    # Evaluate all the individuals against all the testcases.
    # Since the testcase data is large (several gigabytes), evaluate all
    # individuals against each testcase before moving on to the next testcase.
    for testcase_name in USE_TESTCASES:
        logging.info("Evaluating with %s", testcase_name)
        testcase = testcases[testcase_name]

        for ind in population:
            if testcase_name in ind.scores:
                logging.info("Already done individual %s - score %f", ind.hash, ind.scores[testcase_name])
                continue

            ind.write_thresholds()
            decoder_args = ["-f", "transform2d", "--transform-thresholds", ind.thresholds_name]
            psnr, ssim = evaluate(testcase, decoder_args)
            logging.info("Testcase %s individual %s PSNR %f SSIM %f", testcase_name, ind.hash, psnr, ssim)

            ind.scores[testcase_name] = ssim
            ind.write_scores()

    # Compute total score as the product of all scores we're using
    for ind in population:
        ind.total_score = 1.0
        for testcase_name in USE_TESTCASES:
            ind.total_score *= ind.scores[testcase_name]

    # Sort the best individuals first and trim to max size
    population.sort(key=lambda ind: -ind.total_score)
    population = population[:POPULATION_SIZE]

    # Show stats
    logging.info("Generation %d leaderboard:", generation)
    for ind in population:
        logging.info("- %s - total_score %f", ind.hash, ind.total_score)
    total_scores = [ind.total_score for ind in population]
    logging.info("Generation %d: median score %f, best score %f", generation,
                 statistics.median(total_scores), max(total_scores))

    # Generate new children
    new_population = population[:]
    for i in range(NUM_CHILDREN):

        # Choose a parent -- usually the best one
        # XXX This is more an SA than GA approach...
        if choose_random.random() < 0.8:
            parent = population[0]
        else:
            parent = choose_random.choice(population)
        logging.info("child %d mutating from %s", i, parent.hash)

        # Mutate
        # XXX These are all conservative changes -- it may be better to have a "set
        # to random" mutation to avoid getting stuck in a local maximum. (But that
        # may not be a problem depending on what the search space looks like...)
        thresholds = parent.thresholds[:]
        mutation = choose_random.randrange(10)
        if mutation in (0, 1, 2):
            # Raise/lower row
            delta = choose_random.choice([-QUANTUM, QUANTUM])
            y = choose_random.randrange(THRESHOLDS_Y)
            logging.info("raise row %d by %d", y, delta)
            for x in range(THRESHOLDS_X):
                idx = (y * THRESHOLDS_X) + x
                thresholds[idx] = max(0, min(100, thresholds[idx] + delta))
        elif mutation in (3, 4, 5):
            # Raise/lower column
            delta = choose_random.choice([-QUANTUM, QUANTUM])
            x = choose_random.randrange(THRESHOLDS_X)
            logging.info("raise column %d by %d", x, delta)
            for y in range(THRESHOLDS_Y):
                idx = (y * THRESHOLDS_X) + x
                thresholds[idx] = max(0, min(100, thresholds[idx] + delta))
        elif mutation in (6, 7, 8):
            # Raise/lower radius
            delta = choose_random.choice([-QUANTUM, QUANTUM])
            cx = choose_random.randrange(THRESHOLDS_X)
            cy = choose_random.randrange(THRESHOLDS_Y)
            r = choose_random.randrange(min(THRESHOLDS_X, THRESHOLDS_Y))
            logging.info("raise radius %d around %d,%d by %d", r, cx, cy, delta)
            r2 = r * r
            for y in range(THRESHOLDS_Y):
                for x in range(THRESHOLDS_X):
                    if ((cy - y) * (cy - y)) + ((cx - x) * (cx - x)) < r2:
                        idx = (y * THRESHOLDS_X) + x
                        thresholds[idx] = max(0, min(100, thresholds[idx] + delta))
        else: # mutation == 9
            # Crossover - weighted lower because it doesn't seem to be very effective!

            # Select a second parent
            parent2 = parent
            if len(population) > 1:
                while parent.hash == parent2.hash:
                    parent2 = choose_random.choice(population)
            if choose_random.random() > 0.5:
                parent, parent2 = parent2, parent

            # Select a random row or column
            x_split = 0
            y_split = 0
            axis = choose_random.randrange(2)
            if axis == 0:
                x_split = choose_random.randint(1, THRESHOLDS_X - 1)
            elif axis == 1:
                y_split = choose_random.randint(1, THRESHOLDS_Y - 1)

            logging.info("crossover between %s and %s at %d,%d", parent.hash, parent2.hash, x_split, y_split)

            # Join the two halves together
            for y in range(THRESHOLDS_Y):
                for x in range(THRESHOLDS_X):
                    idx = (y * THRESHOLDS_X) + x
                    if x >= x_split and y >= y_split:
                        thresholds[idx] = parent.thresholds[idx]
                    else:
                        thresholds[idx] = parent2.thresholds[idx]

        # Insert the new child, if it doesn't duplicate one we already have
        child = Individual("copy", thresholds)
        for other in new_population:
            if other.hash == child.hash:
                break
        else:
            new_population.append(child)

    population = new_population
    generation += 1
