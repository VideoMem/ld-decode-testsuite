#!/usr/bin/python3
"""
Optimise EFM filters by running test decodes and looking at the statistics
ld-process-efm produces.

This uses a differential evolution approach, based on:

R. Storn, "On the usage of differential evolution for function optimization",
Proceedings of North American Fuzzy Information Processing, Berkeley, CA, USA,
1996, pp. 519-523.
<https://ieeexplore.ieee.org/document/534789>

Kelly Fleetwood, "An Introduction to Differential Evolution"
<https://www.maths.uq.edu.au/MASCOS/Multi-Agent04/Fleetwood.pdf>
"""

import concurrent.futures
import numpy
import os
import pyfftw
import random
import re
import scipy.signal
import scipy.stats
import subprocess
import sys
import tempfile

import commpy_filters

SAMPLE_RATE = 40e6

# Differential evolution parameters
# Population size. This is multiplied by the number of parameters being optimised.
DE_NP = 15
# Scaling factor for the change in the parameter vector.
DE_F = 0.5
# Probability of a new parameter value being taken from the donor.
DE_CR = 0.3

class Candidate:
    """A filter design to be evaluated."""

    def __init__(self, params, generation=0, target=None):
        self.params = params
        self.generation = generation
        self.target = target

        self.futures = {}
        self.results = {}
        self.score = None

    def __str__(self):
        return "Candidate(%s, %s)" % (str(self.params), str(self.generation))

class Testcase:
    """An RF sample that can be decoded."""

    def __init__(self, filename, length):
        self.filename = filename
        self.length = length

        with open(filename, "rb") as f:
            self.data = numpy.fromfile(f, numpy.int16, int(length))

    def __str__(self):
        return self.name()

    def name(self):
        return "Testcase(%s, %d)" % (self.filename, int(self.length))

class Evaluator:
    """Abstract base class for filters being evaluated. Subclasses need to
    override DEFAULT_PARAMS, ADJUST_PARAMS and filter()."""

    # All parameters with default values.
    # name: default
    DEFAULT_PARAMS = {}

    # Parameters to optimise.
    # name: (min, max)
    ADJUST_PARAMS = {}

    def filter(self, params, data):
        """Apply the filter described by params to data. Returns the output of
        the filter."""

        return None

    def evaluate(self, candidate, testcase):
        """Evaluate candidate against testcase: filter testcase's data using the
        candidate filter, then feed it through ld-ldstoefm and ld-process-efm, and
        parse ld-process-efm's log output for statistics.

        Returns a dictionary of statistics."""

        filtered = self.filter(candidate.params, testcase.data)

        if False:
            # Dump to a file for inspection
            with open("/var/tmp/out.s16", "wb") as f:
                filtered.astype(numpy.int16).tofile(f)

        with tempfile.TemporaryDirectory(dir="/var/tmp") as tempdir:
            # Run the PLL
            efm_filename = os.path.join(tempdir, "eval.efm")
            p = subprocess.Popen(["ld-ldstoefm", efm_filename], stdin=subprocess.PIPE, stderr=subprocess.DEVNULL)
            p.stdin.write(filtered.astype(numpy.int16).tobytes())
            p.stdin.close()
            rc = p.wait()
            assert rc == 0

            # XXX do this if rc != 0
            # XXX ld-process-efm pops up a dialog if the input file is empty! Write a dummy file...
            if os.stat(efm_filename).st_size == 0:
                with open(efm_filename, "wb") as f:
                    f.write(bytes([3]))

            # Run ld-process-efm and collect statistics
            p = subprocess.Popen(["ld-process-efm", "-n", efm_filename, "/dev/null"], stdout=subprocess.DEVNULL, stderr=subprocess.PIPE)
            section = None
            counts = {}
            for line in p.stderr.readlines():
                line = line.decode("UTF-8").rstrip()
                if not line.startswith("Info: "):
                    continue
                line = line[6:].lstrip()

                if line.endswith(":"):
                    section = line[:-1]
                    continue

                m = re.match(r'(.*): (\d+)', line)
                if m is not None:
                    name = m.group(1)
                    count = int(m.group(2))

                    if section == "EFM to F3 Frames":
                        if name == "Valid syncs":
                            counts["syncs"] = count
                        elif name == "Valid EFM symbols":
                            counts["symbols"] = count
                        elif name == "Valid frames":
                            counts["frames"] = count
                    elif section == "F3 Frame to F2 Frame decode":
                        if name == "Total input F3 Frames":
                            counts["f3"] = count
                        elif name == "Total output F2 Frames":
                            counts["f2"] = count
                    elif section == "F2 Frames to F1 Frames":
                        if name == "Valid frames":
                            counts["f1"] = count
            p.stderr.close()
            rc = p.wait()
            assert rc == 0

        # Make sure we saw all the stats we expect
        assert len(counts) == 6

        return counts

class LDDEvaluator(Evaluator):
    """Evaluate lddecode_core's filter structure. This won't perform exactly
    the same because the real implementation applies the filters in the
    frequency domain."""

    # lddecode_core's stock parameters
    DEFAULT_PARAMS = {
        "HP_N": 1,
        "HP_f": 0.4e6,
        "LP_twice": True,
        "LP_N": 4,
        "LP_rp": 1.825,
        "LP_rs": 26,
        "LP_f": 2.0e6,
        "S": True,
        "S_N": 221,
        "S_alpha": 0.5,
        "S_Ts": 1/4321800,
        }

    # Parameters to optimise.
    # name: (min, max)
    ADJUST_PARAMS = {
        "HP_f": (0.1e6, 2.0e6),
        "LP_rp": (0.1, 6.0),
        "LP_rs": (10.0, 70.0),
        "LP_f": (1.0e6, 3.0e6),
        }

    def filter(self, params, data):
        filtered = data

        # Apply filters (based on computeefmfilter from ldddecode_core)

        # Highpass
        b, a = scipy.signal.butter(params["HP_N"], [params["HP_f"]], btype="high", fs=SAMPLE_RATE)
        filtered = scipy.signal.lfilter(b, a, filtered)

        # Lowpass
        b, a = scipy.signal.ellip(params["LP_N"], params["LP_rp"], params["LP_rs"], [params["LP_f"]], fs=SAMPLE_RATE)
        filtered = scipy.signal.lfilter(b, a, filtered)
        # This gets applied twice in FFT form
        if params["LP_twice"]:
            filtered = scipy.signal.lfilter(b, a, filtered)

        # Shaping
        if params["S"]:
            ts, hs = commpy_filters.rcosfilter(params["S_N"], params["S_alpha"], params["S_Ts"], SAMPLE_RATE)
            filtered = scipy.signal.lfilter(hs, [1.0], filtered)

        return filtered

class FFTEvaluator(Evaluator):
    """Evaluate an FFT-based filter with amplitude and phase adjustments
    applied in the frequency domain using polynomials.

    This is based on the input signal equaliser in Joe Taylor's WSJT-X."""

    # No amplitude or phase change by default.
    DEFAULT_PARAMS = {
        "a0": 1.0,
        "a1": 0.0,
        "a2": 0.0,
        #"a3": 0.0,
        #"a4": 0.0,
        "p0": 0.0,
        "p1": 0.0,
        "p2": 0.0,
        #"p3": 0.0,
        #"p4": 0.0,
        }

    ADJUST_PARAMS = {k: (-1.0, 1.0) for k in DEFAULT_PARAMS.keys()}
    del ADJUST_PARAMS["p0"] # constant phase offset is pointless

    # FFT size parameters.
    # We will apply the FFT to REAL_SIZE samples at a time, in blocks that
    # overlap by HALF_SIZE samples.
    REAL_SIZE = 1 << 16
    HALF_SIZE = REAL_SIZE // 2
    COMPLEX_SIZE = (REAL_SIZE // 2) + 1

    def filter(self, params, data):
        # Aligned buffers for FFT input/output
        fft_real = pyfftw.empty_aligned(self.REAL_SIZE, numpy.float64)
        fft_complex = pyfftw.empty_aligned(self.COMPLEX_SIZE, numpy.complex128)

        # Plan the forward and inverse FFTs.
        # (This will be expensive the first time only.)
        forward_fft = pyfftw.FFTW(fft_real, fft_complex)
        inverse_fft = pyfftw.FFTW(fft_complex, fft_real,
                                       direction='FFTW_BACKWARD')

        # Symmetric window for the FFT, so we can just add output blocks together
        forward_window = scipy.signal.windows.hann(self.REAL_SIZE, sym=False)

        # Compute the coefficient for each FFT bin by evaluating the polynomials
        indexes = numpy.arange(0, self.COMPLEX_SIZE) / self.COMPLEX_SIZE
        a_coeffs = numpy.zeros(self.COMPLEX_SIZE)
        p_coeffs = numpy.zeros(self.COMPLEX_SIZE)
        for i in range(3):
            a_coeffs += params["a%d" % i] * (indexes ** i)
            p_coeffs += params["p%d" % i] * (indexes ** i)
        # Scale by the amplitude, rotate by the phase
        ap_filter = a_coeffs * (numpy.cos(p_coeffs) + (complex(0, -1) * numpy.sin(p_coeffs)))

        # Work through the input data in HALF_SIZE blocks.
        # We must overlap by half a block at each end.
        length = len(data)
        output = numpy.zeros(length, numpy.float64)
        prev_block = numpy.zeros(self.HALF_SIZE, numpy.int16)
        for pos in range(0, length + self.HALF_SIZE, self.HALF_SIZE):
            # Copy data from the input, padding with zeroes
            right = min(length, pos + self.HALF_SIZE)
            if (right - pos) == self.HALF_SIZE:
                block = data[pos:right]
            else:
                block_right = max(0, right - pos)
                block = numpy.zeros(self.HALF_SIZE, numpy.int16)
                block[:block_right] = data[pos:right]

            # Make up the FFT's input
            fft_real[:self.HALF_SIZE] = prev_block
            fft_real[self.HALF_SIZE:] = block
            prev_block = block

            # Apply the window function and do the FFT.
            # This is a real-to-complex FFT so the result has frequencies 0 to
            # SAMPLE_RATE / 2.
            fft_real *= forward_window
            forward_fft()

            # Apply the frequency-domain filter
            fft_complex *= ap_filter

            # Do the inverse FFT
            inverse_fft()

            # Merge the inverse FFT output into the output buffer
            orig_left = pos - self.HALF_SIZE
            left = max(0, orig_left)
            right = min(length, pos + self.HALF_SIZE)
            output[left:right] += fft_real[left - orig_left:right - orig_left]

        return output

# XXX Better to load only one at a time into memory?
testdir = "/d/extra/laserdisc/audio/"
testcases = [
    # Easy samples
    Testcase(testdir + "fawlty.s16", 1 * SAMPLE_RATE),
    Testcase(testdir + "grateful.s16", 1 * SAMPLE_RATE),
    Testcase(testdir + "thx.s16", 1 * SAMPLE_RATE),
    Testcase(testdir + "wargames.s16", 1 * SAMPLE_RATE),
    Testcase(testdir + "wight.s16", 1 * SAMPLE_RATE),

    # Difficult samples
    Testcase(testdir + "domesday.s16", 1 * SAMPLE_RATE),
    Testcase(testdir + "spinaltap.s16", 1 * SAMPLE_RATE),
    Testcase(testdir + "squibnocket.s16", 1 * SAMPLE_RATE),
    ]

population = []
evaluator = FFTEvaluator()
executor = concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count())

def submit_eval(cand, add=False):
    """Start evaluating cand against all the testcases."""

    if add:
        population.append(cand)
    for testcase in testcases:
        cand.futures[testcase.name()] = executor.submit(evaluator.evaluate, cand, testcase)

def finish_eval(cands):
    """Wait for evaluation to finish for a list of candidates, and compute
    their fitnesses."""

    print("Evaluating", len(cands), end=" ", flush=True)

    winners = 0
    for i, cand in enumerate(cands):
        # Collect any outstanding results
        for name, future in cand.futures.items():
            cand.results[name] = future.result()
        cand.futures = {}

        # Compute fitness
        cand.score = 0
        for testcase in testcases:
            result = cand.results[testcase.name()]
            for name, value in result.items():
                weight = 1
                # More value for correctly-decoded frames
                if name in ("f3", "f2", "f1"):
                    weight = 1000
                cand.score += value * weight

        # Compare with target, if it has one
        dot = "."
        if cand.target is not None:
            if cand.score > population[cand.target].score:
                # Replace it!
                population[cand.target] = cand
                dot = "!"
                winners += 1
            cand.target = None

        # Print progress
        print(dot, end="", flush=True)
        remaining = len(cands) - i
        if (remaining % 20) == 0:
            print(remaining, end="", flush=True)

    print(" ", winners, "improvements")

# Generate the initial population

# Reload from leaderboard, if it exists
try:
    with open("leaderboard", "r") as f:
        print("Loading existing leaderboard...")
        for line in f.readlines():
            fields = line.rstrip().split(",", 2)
            cand = eval(fields[2])
            # XXX Not needed once all files have the generation in anyway
            cand.generation = int(fields[1])
            submit_eval(cand, True)

    generation = max(cand.generation for cand in population)
except FileNotFoundError:
    # Starting from scratch
    generation = 0

if False:
    # Default params, as a baseline
    submit_eval(Candidate(evaluator.DEFAULT_PARAMS), True)

if False:
    # Explore a range of parameters explicitly
    for hp_n in [1]:
        for lp_n in [4]:
            for hp_f in [500]: #range(400, 600, 25):
                for lp_rp in range(1800, 1950, 50):
                    for lp_rs in range(15, 24):
                        for lp_f in range(1800, 2500, 100):
                            params = evaluator.DEFAULT_PARAMS.copy()
                            params.update({
                                "HP_N": hp_n,
                                "HP_f": 0.001e6 * hp_f,
                                "LP_N": lp_n,
                                "LP_rp": 0.001 * lp_rp,
                                "LP_rs": 1.0 * lp_rs,
                                "LP_f": 0.001e6 * lp_f,
                            })
                            submit_eval(Candidate(params), True)

# Fill out the remainder with random candidates
want_population = DE_NP * len(evaluator.ADJUST_PARAMS)
while len(population) < want_population:
    params = evaluator.DEFAULT_PARAMS.copy()
    for name, minmax in evaluator.ADJUST_PARAMS.items():
        params[name] = random.uniform(minmax[0], minmax[1])
    submit_eval(Candidate(params), True)

# Evaluate the initial population
finish_eval(population)

# Evolve
while True:
    generation += 1

    # Sort best first
    population.sort(key=lambda cand: -cand.score)

    # Show the leaderboard
    print()
    print("Generation", generation, "leaderboard")
    print("%-15s %-10s %s" % ("Score", "Generation", "Candidate"))
    for cand in population[:10]:
        print("%-15d %-10d" % (cand.score, cand.generation), str(cand))
        for testcase in testcases:
            print("    %-20s %s" % (os.path.basename(testcase.filename),
                                    str(cand.results[testcase.name()])))
    scores = [cand.score for cand in population]
    print("Scores:", " ".join([str(score) for score in scores]))
    if len(scores) > 1:
        print("Score stats:", scipy.stats.describe(scores))
    print()

    # Save the leaderboard to a file
    with open("leaderboard.new", "w") as f:
        for cand in population:
            f.write("%d,%d,%s\n" % (cand.score, cand.generation, str(cand)))
    os.rename("leaderboard.new", "leaderboard")

    # Generate a trial candidate for each candidate in population, kicking off evaluations as we go
    print("Mutating...")
    trials = []
    popsize = len(population)
    for idx_target, cand_target in enumerate(population):
        while True:
            # Choose three other individuals, all distinct from cand_p
            while True:
                # Use weighted choice for the first -- like the "DE/best" schemes from Storn.
                # Add offset to score so score 0 candidates can still be chosen sometimes.
                idx_1 = random.choices(range(popsize), weights=[cand.score + 1000 for cand in population])[0]
                idx_2 = random.randrange(popsize)
                idx_3 = random.randrange(popsize)
                if len(set([idx_target, idx_1, idx_2, idx_3])) == 4:
                    break
            cand_1 = population[idx_1]
            cand_2 = population[idx_2]
            cand_3 = population[idx_3]

            # Build params for the new trial candidate
            trial_params = cand_target.params.copy()
            for name, minmax in evaluator.ADJUST_PARAMS.items():
                # Replace this param?
                if random.random() < DE_CR:
                    # Yes - compute the donor value for it
                    trial_params[name] = cand_1.params[name] + (DE_F * (cand_2.params[name] - cand_3.params[name]))

            # Are all the params in range?
            if all(trial_params[name] >= minmax[0]
                   and trial_params[name] <= minmax[1]
                   for name, minmax in evaluator.ADJUST_PARAMS.items()):
                break

        trial = Candidate(trial_params, generation, idx_target)
        submit_eval(trial)
        trials.append(trial)

    # Finish evaluations, inserting successful trials into population
    finish_eval(trials)
